{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Convolucionales\n",
    "\n",
    "En este _notebook_ vamos a ver cómo construir una red convolucional con Keras. El _dataset_ que vamos a usar es el de [gatos vs perros de Kaggle](https://www.kaggle.com/chetankv/dogs-cats-images). Este tutorial está inspirado en [este post](https://medium.com/@apoorvgupta00/binary-classification-cats-vs-dogs-tutorial-using-tensorflow2-and-keras-bbe07f723d75)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "import math\n",
    "\n",
    "data_dir = 'dataset' \n",
    "os.listdir(data_dir)  \n",
    "test_p = data_dir + '/test_set/'\n",
    "train_p = data_dir + '/training_set/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí vamos a ver las dimensiones de las imágenes para normalizar los tamaños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356.267\n",
      "413.064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(357, 414, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension1 = []\n",
    "dimension2 = []\n",
    "\n",
    "for i_file in os.listdir(test_p+'cats'):\n",
    "\timg= imread(test_p + 'cats/' + i_file)\n",
    "\tx, y, colors = img.shape\n",
    "\tdimension1.append(x)\n",
    "\tdimension2.append(y)\n",
    "    \n",
    "print(np.mean(dimension1))\n",
    "print(np.mean(dimension2)) \n",
    "image_shape = (math.ceil(np.mean(dimension1)), math.ceil(np.mean(dimension2)), 3)\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí vamos a hacer un truco común. Vamos a modificar ligeramente los datos que tenemos con la clase `ImageDataGenerator`. La idea es ir rotando las imágenes y cambiar su alto y ancho, para así generar imágenes a partir de las existentes. Vamos a ver más adelante que deduce el nombre de las clases de los subdirectorios del _dataset_ de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "<tensorflow.python.keras.preprocessing.image.DirectoryIterator object at 0x13a897eb0>\n",
      "Found 2000 images belonging to 2 classes.\n",
      "<tensorflow.python.keras.preprocessing.image.DirectoryIterator object at 0x13a7f7730>\n"
     ]
    }
   ],
   "source": [
    "image_gen = ImageDataGenerator(rotation_range=10, \n",
    "                               width_shift_range=0.10, \n",
    "                               height_shift_range=0.10, \n",
    "                               rescale=1/255)\n",
    "\n",
    "# Rescale nos sirve para pasar de valores del 0 al 255 a valores entre 0 y 1. \n",
    "\n",
    "print(image_gen.flow_from_directory(train_p))\n",
    "print(image_gen.flow_from_directory(test_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a instanciar el modelo secuencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 355, 412, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 177, 206, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 175, 204, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 87, 102, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 283968)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                18174016  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 18,184,225\n",
      "Trainable params: 18,184,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(filters=32, kernel_size=(3,3), input_shape=image_shape, activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1), # Queremos una neurona final con una probabilidad, dado que es clasificación binaria.\n",
    "        Activation('sigmoid')\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, aquí tenemos hartas capas. Las capas `Conv2D` son las capas convolucionales. La primera capa tiene 32 filtros de $3\\times3$. El tamaño del input es `input_shape` y la activación es ReLU. Luego agregamos una capa de pooling de tamaño 2x2. En este caso no estamos añadiendo un tamaño del _stride_ en la capa de _pooling_ y por defecto será del mismo tamaño que `pool_size`. La última capa nueva es `Dropout`. Esta capa desactiva (les asigna valor 0) de forma aleatoria la mitad (0.5 = 50%) de las neuronas de la última capa en la fase de entrenamiento. Esto se usa para preveenir el _overfitting_. Ahora compilaremos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El optimizador ADAM es un (a grandes rasgos) SGD optimizado\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora lo vamos a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "# target_size me indica el tamaño al que redimensionamos la imagen\n",
    "train_image_gen = image_gen.flow_from_directory(train_p, \n",
    "                                                target_size=image_shape[:2], \n",
    "                                                color_mode='rgb', \n",
    "                                                batch_size=batch_size, \n",
    "                                                class_mode='binary')\n",
    "test_image_gen = image_gen.flow_from_directory(test_p, \n",
    "                                               target_size=image_shape[:2], \n",
    "                                               color_mode='rgb', \n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='binary',\n",
    "                                               shuffle=False)\n",
    "train_image_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 699s 3s/step - loss: 0.7049 - accuracy: 0.5775\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 626s 3s/step - loss: 0.6509 - accuracy: 0.6239\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 624s 2s/step - loss: 0.6369 - accuracy: 0.6351\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 669s 3s/step - loss: 0.6069 - accuracy: 0.6701\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 828s 3s/step - loss: 0.5784 - accuracy: 0.7025\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 685s 3s/step - loss: 0.5624 - accuracy: 0.7131\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 748s 3s/step - loss: 0.5482 - accuracy: 0.7245\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 658s 3s/step - loss: 0.5231 - accuracy: 0.7481\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 626s 3s/step - loss: 0.5204 - accuracy: 0.7430\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 623s 2s/step - loss: 0.5157 - accuracy: 0.7480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x109584880>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_image_gen, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora veremos cómo funciona la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75      1000\n",
      "           1       0.76      0.71      0.74      1000\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.75      0.75      0.75      2000\n",
      "weighted avg       0.75      0.75      0.75      2000\n",
      "\n",
      "[[782 218]\n",
      " [291 709]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "pred_probabilities = model.predict(test_image_gen)\n",
    "predictions = pred_probabilities > 0.5\n",
    "print(classification_report(test_image_gen.classes, predictions))\n",
    "print(confusion_matrix(test_image_gen.classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
